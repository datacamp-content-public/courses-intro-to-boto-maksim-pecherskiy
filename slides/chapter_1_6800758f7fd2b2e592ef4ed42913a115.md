---
title: Insert title here
key: 6800758f7fd2b2e592ef4ed42913a115

---
## Working with objects in buckets

```yaml
type: "TitleSlide"
key: "dd7c97db8a"
```

`@lower_third`

name: Maksim Pecherskiy
title: Chief Data Officer, City of San Diego


`@script`
In the last set of exercises, you learned how to list, create and delete buckets.  This will let you create custom containers as part of your data pipeline.  Now that we have these buckets, it's time to put stuff in them.  The files within AWS buckets are called objects.  And an object can really be anything - an image, a video file, CSVs, or log files.  Working with files in S3 is where Boto becomes really useful for your data pipeline work.  Uploading, downloading, and iterating over objects in S3 buckets is a key component of many pipelines.  Let's take a look at how objects work.


---
## How buckets and objects work together.

```yaml
type: "TwoColumns"
key: "5b3c400989"
```

`@part1`
- Object has only one parent bucket {{2}}
- Object knows about their parent bucket {{3}}
- Buckets contain many objects {{4}}
- Buckets can list their own objects {{5}}


`@part2`
![Bucket with objects](http://take.ms/Cvy4Z)


`@script`
Objects in AWS and in Boto are sub resources.  
That means that every object has one parent bucket.  
An object can't exist without a bucket.  

Objects know about their parent bucket and can get a reference to it.

Buckets can contain many objects, and they know how to list their own objects.


---
## Creating an object in a bucket.

```yaml
type: "TwoColumns"
key: "1bbc4a6e51"
center_content: true
```

`@part1`
```python
s3 = boto3.resource('s3', region_name='us-east-1', aws_access_key_id=AWS_KEY_ID, aws_secret_access_key=AWS_SECRET)
```


`@part2`
![](http://take.ms/thCaI)


`@script`
This is the empty bucket we created in the last set of exercises.  You may remember the cool name we gave it too - datacamp-trout.  Continuing along with our fish monitoring example, when you walk into work every morning, there's a file in your email.  You want to take that file and upload it to S3 with the current date as a suffix.  
	* File appears in bucket.  Code shown.
	* We are going to create our s3.resource variable as before.
	* We are going to create our bucket variable to have a pointer to the bucket we are working with.
	* And then, we will tell the bucket what we want to upload this latest trout data CSV with a specific file name.  Now we  can see that the file has been successfully uploaded to the bucket.


---
## Object Operations

```yaml
type: "TwoRowsTwoColumns"
key: "f9498f915c"
center_content: false
```

`@part1`
### Create / Update 
Hello{{2}}


`@part2`
### Read


`@part3`
### List


`@part4`
### Delete


`@script`
Just like buckets, S3 objects are also Boto objects, allowing us to perform operations them.  For


---
## Final Slide

```yaml
type: "FinalSlide"
key: "e91c9c8136"
```

`@script`


