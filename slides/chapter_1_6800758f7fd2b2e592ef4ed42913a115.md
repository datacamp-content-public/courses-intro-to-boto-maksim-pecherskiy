---
title: Insert title here
key: 6800758f7fd2b2e592ef4ed42913a115

---
## Working with objects in buckets

```yaml
type: "TitleSlide"
key: "dd7c97db8a"
```

`@lower_third`

name: Maksim Pecherskiy
title: Chief Data Officer, City of San Diego


`@script`
In the last set of exercises, you learned how to list, create and delete buckets.    

Now, it's time to put stuff in them. The files within S3 buckets are called objects.  

An object can be anything - an image, a video file, CSV or a log file.  

Managing objects, and getting their metadata is a key component of many data pipelines.  

Let's take a look at how objects work.


---
## How buckets and objects work together.

```yaml
type: "TwoColumns"
key: "5b3c400989"
```

`@part1`
- A bucket has **many** objects {{1}}
- An object has only **one** parent bucket {{1}}
- A bucket can **list** its **child** objects {{2}}
- An object can **access** its **parent** bucket {{2}}
- A bucket has a **unique** name in all of S3.{{3}}
- An object has a **unique** key {{3}}


`@part2`
![Bucket with objects](http://take.ms/Cvy4Z){{1}}


`@script`
Objects and buckets in S3 work somewhat  like files and folders on your desktop. Buckets contain objects.  When you interact with them in boto, they are sub-resources of each  other.

A bucket has many objects. But an object has only one parent bucket.

--

A bucket can list its child objects, and an object can access its parent bucket.

--

A bucket has a unique name in all of S3. 
An object has a key  (or filename) unique to each bucket.

--

Let's look at how some specific object operations.


---
## Creating objects in buckets.

```yaml
type: "TwoColumns"
key: "1bbc4a6e51"
center_content: false
```

`@part1`
**Create resource** {{1}}
```python
s3_resource = boto3.resource('s3')
```{{1}}

**Create reference to the object to be created**{{2}}
```python
trout_file = s3_resource.Object(
    bucket_name='datacamp-trout',
    key='trout_obs_2019-01-27.csv')
```{{2}}

**Upload**{{3}}
```python
trout_file.upload_file(
     Filename='./trout_obs.csv')
```{{3}}


`@part2`
![](http://take.ms/Cxv7Y){{4}}


`@script`
Take the empty bucket we created in the last lesson. You may remember the cool name we gave it - datacamp-trout. In this magical fish-monitoring place where you work, you walk into work every morning to find a file in your e-mail with the latest trout monitoring data. Let's upload this file to S3 with the current date as part of the file name.


First create your resource instance by calling the boto3 resource method with the argument 's3'.

--

Then, create a new instance of an object, passing bucket name and key as parameters. 

--

This does not mean there is an object in the bucket yet. It's just a reference, and right now it points to an empty space.

Fill that empty space with the contents of trout_obs.csv. Call the object instance's upload_file method, and pass the local file name as an argument.  

--

Whoo! You created and uploaded an object to S3.

--
To update a file, use its key to overwrite it. You have to be careful to make sure you are not overwriting something you need.


---
## Downloading an object from a bucket.

```yaml
type: "TwoColumns"
key: "3247ac6027"
disable_transition: true
```

`@part1`
**Create resource** {{1}}
```python
s3_resources = boto3.resource('s3')
```{{1}}

**Create reference to existing object**{{2}}
```python
trout_file = s3_resource.Object(
    bucket_name='datacamp-trout',
    key='trout_obs_2019-01-27.csv')
```{{2}}

**Download!**{{3}}
```python
trout_file.download_file(
    Filename='./trout_obs_dl_s3.csv'
)
```{{3}}


`@part2`
![](http://take.ms/Cxv7Y)


`@script`
Downloading is very similar to uploading.

Create the resource instance.

--

Create an object instance. This time, the object already exists on S3.

--

Download, specifying where the file should be stored locally using the Filename argument.


---
## Getting metadata

```yaml
type: "TwoColumns"
key: "371a178992"
disable_transition: false
```

`@part1`
**File Size**{{1}}
```python
trout_file.content_length
``` {{1}}

**Last Modified Date **{{2}}
```python
trout_file.last_modified
```{{2}}


`@part2`
![](http://take.ms/QFyU2)


`@script`
There are some other cool things you can do with a reference. Let's look at how to get metadata about the object.

--

The content_length property contains the object size in bytes.

--

The last_modified property is a Python datetime of the last time this object was changed.


---
## Getting metadata

```yaml
type: "TwoColumns"
key: "9d5a08d789"
disable_transition: true
```

`@part1`
**Bucket Name**{{1}}
```python
trout_file.bucket_name
``` {{1}}

** Bucket Reference **{{2}}
```python
bucket = trout_file.Bucket
```{{2}}


`@part2`
![](http://take.ms/QFyU2)


`@script`
--
The bucket_name property contains the name of the object's parent bucket.

--
Lastly, the object has a Bucket instance attached to it.  This instance lets you interact with the object's parent bucket.

--


---
## Deleting an object from a bucket.

```yaml
type: "TwoColumns"
key: "856278d9b5"
```

`@part1`
**Create resource** {{1}}
```python
s3_resource = boto3.resource('s3')
```{{1}}

**Delete!**{{2}}
```python
s3_resource.Object(
    bucket_name='datacamp-trout',
    key='trout_obs_2019-01-27.csv'
).delete()
```{{2}}


`@part2`
![](https://s3.amazonaws.com/mrm-screen/S3_Management_Console_2019-01-27_13-18-36.png){{3}}


`@script`
Deleting an object follows the same pattern as uploading and downloading.  This time, chain your code together so it's more concise:

--

Create the resource instance.
--

Instead of creating a reference to the object and  storing it in a variable, create the reference and call delete() on the object. 

-- 

Now our object is gone!


---
## Summary (uploading)

```yaml
type: "TwoColumns"
key: "47b7a07aa2"
```

`@part1`
**Create resource and reference**{{1}}

```python
s3_resource = boto3.resource('s3')

trout_file = s3_resource.Object(
    bucket_name='datacamp-trout',
    key='trout_obs_2019-01-27.csv')
```{{1}}

**Upload**{{2}}
```python
trout_file.upload_file(
     Filename='./trout_obs.csv')
```{{2}}


`@part2`
![](http://take.ms/hIJKd){{2}}


`@script`
In this lesson you learned how to create, upload and update objects.


---
## Summary (downloading)

```yaml
type: "TwoColumns"
key: "d1a40fc99d"
disable_transition: true
```

`@part1`
**Create resource and reference**
```python
s3_resource = boto3.resource('s3')

trout_file = s3_resource.Object(
    bucket_name='datacamp-trout',
    key='trout_obs_2019-01-27.csv')
```
`



**Download!**{{1}}
```python
trout_file.download_file(
    Filename='./trout_obs_dl_s3.csv'
)
```{{1}}


`@part2`
![](http://take.ms/OT3r5){{1}}


`@script`
You learned how to download objects.


---
## Summary (getting metadata)

```yaml
type: "TwoColumns"
key: "305c2db8e3"
disable_transition: true
```

`@part1`
**Create resource and reference**
```python
s3_resource = boto3.resource('s3')

trout_file = s3_resource.Object(
    bucket_name='datacamp-trout',
    key='trout_obs_2019-01-27.csv')
```
`

** Get Metadata **{{1}}
```python
trout_file.content_length
trout_file.bucket_name
trout_file.last_modified
```{{1}}


`@part2`
![](http://take.ms/Tla7Z){{1}}


`@script`
You learned how to get object metadata.


---
## Summary (deleting)

```yaml
type: "TwoColumns"
key: "b424c44315"
```

`@part1`
**Create resource and reference**
```python
s3_resource = boto3.resource('s3')

trout_file = s3_resource.Object(
    bucket_name='datacamp-trout',
    key='trout_obs_2019-01-27.csv')
```
`

** Delete **{{1}}
```python
trout_file.delete()
```{{1}}


`@part2`
![](http://take.ms/GudCZ){{1}}


`@script`
And finally, how to delete objects.


---
## Let's practice!

```yaml
type: "FinalSlide"
key: "e91c9c8136"
```

`@script`
Now, let's practice!

